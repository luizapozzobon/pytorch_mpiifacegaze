{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPIIFaceGazeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subject_id, dataset_dir):\n",
    "        path = os.path.join(dataset_dir, '{}.h5'.format(subject_id))\n",
    "        dataset = h5py.File(path)\n",
    "        \n",
    "        self.images = dataset['data']\n",
    "        self.gazes = dataset['label']\n",
    "\n",
    "        self.length = len(self.images)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # original shape: [channel[BGR], x, y]\n",
    "        # [2, 1, 0] reshapes BGR to RGB [channel[RGB], x, y]\n",
    "        # couple of transposes to put image to correct representation\n",
    "        # first one puts channel dim last and brings forward the y dim [y, x, channel[RGB]]\n",
    "        # second brings forward the x dim and puts y dim second [x, y, channel[RGB]]\n",
    "        img = torch.from_numpy((self.images[index][[2, 1, 0],:,:])).transpose(2, 0).transpose(1, 0)\n",
    "        gaze = torch.from_numpy(self.gazes[index][0:2])\n",
    "        return img, gaze\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(dataset_dir, test_subject_id, batch_size, num_workers, use_gpu):\n",
    "    assert os.path.exists(dataset_dir)\n",
    "    assert test_subject_id in range(15)\n",
    "\n",
    "    base_subject_ids = ['p{:02}'.format(i) for i in range(15)]\n",
    "    base_test_subject_id = base_subject_ids[test_subject_id]\n",
    "    \n",
    "    test_subject_ids = []\n",
    "    subject_ids = []\n",
    "    for i, subject_id in enumerate(base_subject_ids):\n",
    "        for file_part in range(2):\n",
    "            subject_ids.append(subject_id + '_' + str(file_part))\n",
    "    \n",
    "    for file_part in range(2):\n",
    "        test_subject_ids.append(base_test_subject_id + '_' + str(file_part))\n",
    "    \n",
    "    train_dataset = torch.utils.data.ConcatDataset([\n",
    "        MPIIFaceGazeDataset(subject_id, dataset_dir) for subject_id in subject_ids\n",
    "        if subject_id not in test_subject_ids\n",
    "    ])\n",
    "    \n",
    "    test_dataset = torch.utils.data.ConcatDataset([\n",
    "        MPIIFaceGazeDataset(i, dataset_dir) for i in test_subject_ids\n",
    "    ])\n",
    "    \n",
    "    assert len(train_dataset) == 42000\n",
    "    assert len(test_dataset) == 3000\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=use_gpu,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=use_gpu,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_data = MPIIFaceGazeDataset('p00_1', \"/media/luiza/HDLuiza/Dataset/Gaze/MPIIFaceGaze_normalizad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, gaze = face_data.__getitem__(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.numpy().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.fromarray(img, 'RGB')\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
